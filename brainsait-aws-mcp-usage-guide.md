# üß† BrainSAIT LincCore‚Ñ¢ + AWS MCP Healthcare Integration Guide

**NEURAL:** Advanced healthcare AI with AWS MCP server connectivity  
**BRAINSAIT:** HIPAA + NPHIES compliance with enterprise-grade AWS integration  
**MEDICAL:** Complete FHIR R4 + AWS HealthLake + HealthOmics integration  
**BILINGUAL:** Arabic/English healthcare AI with AWS Comprehend Medical  

---

## üöÄ Quick Start

### Prerequisites

**BRAINSAIT:** System Requirements
- Docker & Docker Compose
- Python 3.11+
- AWS CLI v2
- UV (Python package manager)
- Minimum 16GB RAM, 32GB recommended
- AWS Account with healthcare services enabled

**MEDICAL:** AWS Healthcare Services Access
- AWS HealthLake (FHIR R4 datastore)
- AWS HealthOmics (Genomics workflows)
- AWS Comprehend Medical (Medical NLP)
- Appropriate IAM permissions for healthcare services

### 1. Clone and Setup

```bash
# Clone your BrainSAIT repository
git clone https://github.com/your-org/brainsait-linccore.git
cd brainsait-linccore

# Make deployment script executable
chmod +x scripts/deploy-aws-mcp.sh

# Deploy the complete integration
./scripts/deploy-aws-mcp.sh deploy
```

### 2. Configure AWS Healthcare Services

**MEDICAL:** Update your `.env.aws` file:

```bash
# AWS Configuration
AWS_REGION=us-east-1
AWS_PROFILE=brainsait-healthcare

# HealthLake Configuration  
HEALTHLAKE_DATASTORE_ID=your_actual_datastore_id
HEALTHLAKE_ENDPOINT=https://healthlake.us-east-1.amazonaws.com

# HealthOmics Configuration
HEALTHOMICS_WORKFLOW_ID=your_workflow_id

# Compliance Settings
HIPAA_COMPLIANCE=strict
NPHIES_INTEGRATION=enabled
AUDIT_LEVEL=comprehensive
```

### 3. Access the Platform

**NEURAL:** Service Endpoints:
- üéØ **MCP Gateway**: http://localhost:8080
- üè• **HealthLake MCP**: http://localhost:8090  
- üß¨ **HealthOmics MCP**: http://localhost:8091
- üéØ **Core MCP**: http://localhost:8092
- üìä **Grafana Dashboard**: http://localhost:3000
- üîç **Prometheus**: http://localhost:9090

---

## üè• AWS HealthLake Integration

### FHIR R4 Operations

**MEDICAL:** Creating FHIR Patient Records:

```python
from brainsait.aws_mcp import AWSMCPEnabledAgent, MCPHealthLakeRequest

# Initialize enhanced HEALTHCARELINC agent
agent = AWSMCPEnabledAgent(
    name="HEALTHCARELINC_AWS",
    capabilities=[AgentCapability.FHIR_PROCESSING],
    aws_region="us-east-1"
)

# Initialize with HealthLake datastore
await agent.initialize_healthcare_mcp_servers(
    healthlake_datastore_id="your-datastore-id",
    enable_healthomics=True
)

# Create FHIR Patient resource
patient_data = {
    "resourceType": "Patient",
    "id": "patient-123",
    "name": [
        {
            "family": "ÿßŸÑÿ£ÿ≠ŸÖÿØ",  # Arabic family name
            "given": ["ÿ£ÿ≠ŸÖÿØ", "ŸÖÿ≠ŸÖÿØ"]
        }
    ],
    "gender": "male",
    "birthDate": "1985-06-15",
    "address": [
        {
            "city": "ÿßŸÑÿ±Ÿäÿßÿ∂",
            "country": "SA",
            "postalCode": "12345"
        }
    ]
}

# Execute FHIR operation
request = MCPHealthLakeRequest(
    action="create_resource",
    resource_type="Patient",
    fhir_data=patient_data
)

result = await agent.aws_mcp_bridge.healthlake_fhir_operation(request)
```

**MEDICAL:** Searching FHIR Resources:

```python
# Search for patients by name
search_request = MCPHealthLakeRequest(
    action="search_resources",
    resource_type="Patient",
    search_params={
        "family": "ÿßŸÑÿ£ÿ≠ŸÖÿØ",
        "gender": "male",
        "_count": 10
    }
)

search_results = await agent.aws_mcp_bridge.healthlake_fhir_operation(search_request)
```

### Clinical Workflow Integration

**AGENT:** AI-Powered Clinical Workflows:

```python
# Execute comprehensive FHIR workflow
fhir_resources = [
    {
        "resourceType": "Patient", 
        "name": [{"family": "ÿßŸÑÿ£ÿ≠ŸÖÿØ", "given": ["ÿ£ÿ≠ŸÖÿØ"]}]
    },
    {
        "resourceType": "Encounter",
        "status": "in-progress",
        "subject": {"reference": "Patient/patient-123"}
    },
    {
        "resourceType": "Observation",
        "status": "final",
        "code": {"coding": [{"code": "8480-6", "system": "http://loinc.org"}]},
        "valueQuantity": {"value": 120, "unit": "mmHg"}
    }
]

workflow_result = await agent.execute_fhir_workflow(
    workflow_type="patient_admission",
    fhir_resources=fhir_resources,
    patient_id="patient-123"
)
```

---

## üß¨ AWS HealthOmics Integration

### Genomics Workflow Management

**MEDICAL:** Creating Genomic Analysis Workflows:

```python
from brainsait.aws_mcp import MCPHealthOmicsRequest

# Define genomics workflow (WDL example)
workflow_definition = {
    "workflow_language": "WDL",
    "workflow_name": "variant-calling-pipeline",
    "main_workflow_file": "variant_calling.wdl",
    "parameter_template": {
        "input_vcf": "s3://genomics-data/sample.vcf",
        "reference_genome": "s3://reference/hg38.fa"
    }
}

# Create workflow
workflow_request = MCPHealthOmicsRequest(
    action="create_workflow",
    workflow_definition=workflow_definition
)

workflow_result = await agent.aws_mcp_bridge.healthomics_workflow_operation(workflow_request)
```

**AGENT:** Running Genomic Analysis:

```python
# Execute genomics workflow
input_data = {
    "sample_vcf": "s3://patient-genomics/patient-123/variants.vcf.gz",
    "reference_genome": "hg38",
    "analysis_type": "variant_calling",
    "output_bucket": "s3://results/patient-123/"
}

run_request = MCPHealthOmicsRequest(
    action="start_run", 
    workflow_id="workflow-abc123",
    input_parameters=input_data
)

genomics_result = await agent.execute_genomics_workflow(
    workflow_definition=workflow_definition,
    input_data=input_data
)
```

### Genomics Results Integration with FHIR

**MEDICAL:** Converting Genomics Results to FHIR:

```python
# Create FHIR Genomics resources from HealthOmics results
genomics_observation = {
    "resourceType": "Observation",
    "status": "final",
    "category": [
        {
            "coding": [
                {
                    "system": "http://terminology.hl7.org/CodeSystem/observation-category",
                    "code": "survey",
                    "display": "Survey"
                }
            ]
        }
    ],
    "code": {
        "coding": [
            {
                "system": "http://loinc.org",
                "code": "69548-6",
                "display": "Genetic analysis master panel"
            }
        ]
    },
    "subject": {"reference": "Patient/patient-123"},
    "component": [
        {
            "code": {
                "coding": [
                    {
                        "system": "http://loinc.org", 
                        "code": "48013-7",
                        "display": "Genomic reference sequence ID"
                    }
                ]
            },
            "valueString": "hg38"
        }
    ]
}

# Store genomics results in HealthLake
genomics_request = MCPHealthLakeRequest(
    action="create_resource",
    resource_type="Observation",
    fhir_data=genomics_observation
)

result = await agent.aws_mcp_bridge.healthlake_fhir_operation(genomics_request)
```

---

## üéØ AWS Core MCP Integration

### Multi-Service Healthcare Orchestration

**NEURAL:** Using Core MCP for Healthcare Architecture:

```python
# Core MCP server provides comprehensive AWS guidance
core_request = {
    "method": "tools/call",
    "params": {
        "name": "prompt_understanding",
        "arguments": {
            "prompt": """
            I need to build a HIPAA-compliant healthcare data pipeline that:
            1. Ingests HL7 FHIR data from multiple EHR systems
            2. Processes medical text with Arabic support
            3. Stores data in HealthLake with encryption
            4. Runs genomics workflows in HealthOmics
            5. Provides real-time analytics dashboard
            6. Ensures NPHIES compliance for Saudi Arabia
            
            What AWS architecture and services should I use?
            """
        }
    }
}

# Execute through Core MCP bridge
core_result = await agent.aws_mcp_bridge._send_mcp_request(
    MCPServerType.CORE, 
    core_request
)
```

---

## üìä Monitoring & Compliance

### Health Monitoring Dashboard

**BRAINSAIT:** Access Grafana at http://localhost:3000:

- üè• **AWS MCP Services Health**: Real-time status of all MCP bridges
- üß¨ **HealthLake FHIR Operations**: FHIR resource creation/update rates
- üìä **MCP Response Times**: 95th/50th percentile response times
- üîê **PHI Access Monitoring**: Protected health information access tracking
- üß¨ **HealthOmics Workflow Status**: Genomics pipeline execution status
- üí∞ **AWS Cost Tracking**: Real-time cost monitoring

### Compliance Monitoring

**BRAINSAIT:** HIPAA Audit Trail:

```python
# Query audit logs for compliance reporting
audit_query = """
SELECT 
    mcp_server_type,
    action,
    phi_accessed,
    hipaa_compliant,
    timestamp,
    user_id,
    resource_type
FROM aws_mcp_audit_logs 
WHERE timestamp >= NOW() - INTERVAL '24 hours'
    AND phi_accessed = TRUE
ORDER BY timestamp DESC;
"""

# Generate compliance report
compliance_report = await agent.audit_logger.generate_compliance_report(
    start_date="2024-01-01",
    end_date="2024-01-31",
    include_phi_access=True,
    include_nphies_data=True
)
```

**MEDICAL:** NPHIES Integration Status:

```python
# Check NPHIES compliance status
nphies_status = await agent.nphies_integration.check_compliance_status()

if nphies_status["compliant"]:
    print("‚úÖ NPHIES compliance verified")
    print(f"Standards version: {nphies_status['standards_version']}")
    print(f"Arabic terminology: {nphies_status['arabic_support']}")
else:
    print("‚ö†Ô∏è NPHIES compliance issues detected")
    for issue in nphies_status["issues"]:
        print(f"   - {issue}")
```

---

## üîß Advanced Configuration

### Custom MCP Server Configuration

**NEURAL:** Extending with Custom Healthcare MCP Servers:

```python
# Register custom healthcare MCP server
custom_config = MCPServerConfig(
    server_type="custom-radiology-mcp",
    command="uvx",
    args=["your-custom-radiology-mcp-server"],
    env_vars={
        "DICOM_INTEGRATION": "enabled",
        "PACS_ENDPOINT": "https://your-pacs-system.com",
        "ARABIC_RADIOLOGY_TERMS": "enabled"
    },
    hipaa_enabled=True,
    fhir_validation=True,
    arabic_nlp_support=True
)

await agent.aws_mcp_bridge.register_mcp_server(custom_config)
```

### Multi-Language Medical NLP

**BILINGUAL:** Arabic Medical Text Processing:

```python
# Process Arabic medical text with AWS Comprehend Medical
arabic_clinical_note = """
ÿßŸÑŸÖÿ±Ÿäÿ∂ Ÿäÿ¥ŸÉŸà ŸÖŸÜ ÿ£ŸÑŸÖ ŸÅŸä ÿßŸÑÿµÿØÿ± ŸÖŸÜÿ∞ ÿ≥ÿßÿπÿ™ŸäŸÜ. 
ÿ∂ÿ∫ÿ∑ ÿßŸÑÿØŸÖ: Ÿ°Ÿ§Ÿ†/Ÿ©Ÿ† ŸÖŸÑŸÖ ÿ≤ÿ¶ÿ®ŸÇ
ÿßŸÑŸÜÿ®ÿ∂: Ÿ©Ÿ• ŸÜÿ®ÿ∂ÿ© ŸÅŸä ÿßŸÑÿØŸÇŸäŸÇÿ©
ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ ÿßŸÑŸÖÿ®ÿØÿ¶Ÿä: ÿ∞ÿ®ÿ≠ÿ© ÿµÿØÿ±Ÿäÿ© ŸÖÿ≠ÿ™ŸÖŸÑÿ©
"""

# Use AWS Comprehend Medical for Arabic text analysis
comprehend_request = {
    "text": arabic_clinical_note,
    "language": "ar",
    "extract_entities": True,
    "extract_relationships": True,
    "extract_phi": True